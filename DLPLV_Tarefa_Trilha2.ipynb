{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Trilha2_Ferramentas.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "BKpVuQpatfOI",
        "PfOciqM_thZ1",
        "JrAUMu8Au6EN",
        "LaEE5llC4nKO",
        "GbWOiO2I5Fx3"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Importando as bibliotecas"
      ],
      "metadata": {
        "id": "KL_8ND0jlMDd"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oi7czSpNM11B"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU4N5GZyvDMi"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-sg3u8HjhEB"
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Carregando os dados"
      ],
      "metadata": {
        "id": "XrE1BsaTlWR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_csv(\"https://raw.githubusercontent.com/jrandrade07/DataSets/main/OSI_feats_e3.csv\")\n",
        "y = pd.read_csv(\"https://raw.githubusercontent.com/jrandrade07/DataSets/main/OSI_target_e2.csv\")"
      ],
      "metadata": {
        "id": "_tQBBc0ajth9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123)"
      ],
      "metadata": {
        "id": "70sgiHoWmfdS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKpVuQpatfOI"
      },
      "source": [
        "# Modelo Sequencial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v23iXU25tsCL"
      },
      "source": [
        "from keras.models import Sequential"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBXFMQ7KthGG"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4, input_dim=1))\n",
        "model.add(Dense(1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBieenYm0DJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "10c64ce1-61b7-42d6-e259-84e25c8ae656"
      },
      "source": [
        "plot_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96PAPXRz7Ux6"
      },
      "source": [
        "# Construindo um Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFLcMzMc7wVY"
      },
      "source": [
        "# 2. Definir o modelo\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VicqfhTJkakt",
        "outputId": "82a700d1-7216-4edb-9b83-4f615ae3701c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5ItSVz8jkVp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eaea834-71c7-42f6-8832-e161148fd625"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 12)                828       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 941\n",
            "Trainable params: 941\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3t2J3Mms7zp8"
      },
      "source": [
        "# 3. Compilar o modelo\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Al1wF4ye73xm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "227371d4-7c80-4891-9e55-fa53b71a52c0"
      },
      "source": [
        "# 4. Ajustar o modelo aos dados\n",
        "model.fit(X, y, epochs=150, batch_size=10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1233/1233 [==============================] - 4s 2ms/step - loss: 1.8362 - accuracy: 0.8389\n",
            "Epoch 2/150\n",
            "1233/1233 [==============================] - 5s 4ms/step - loss: 0.4265 - accuracy: 0.8682\n",
            "Epoch 3/150\n",
            "1233/1233 [==============================] - 4s 3ms/step - loss: 0.4072 - accuracy: 0.8663\n",
            "Epoch 4/150\n",
            "1233/1233 [==============================] - 4s 3ms/step - loss: 0.3547 - accuracy: 0.8757\n",
            "Epoch 5/150\n",
            "1233/1233 [==============================] - 6s 4ms/step - loss: 0.3331 - accuracy: 0.8765\n",
            "Epoch 6/150\n",
            "1233/1233 [==============================] - 3s 2ms/step - loss: 0.3117 - accuracy: 0.8792\n",
            "Epoch 7/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.3100 - accuracy: 0.8775\n",
            "Epoch 8/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2920 - accuracy: 0.8812\n",
            "Epoch 9/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2835 - accuracy: 0.8833\n",
            "Epoch 10/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2747 - accuracy: 0.8839\n",
            "Epoch 11/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2706 - accuracy: 0.8895\n",
            "Epoch 12/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2626 - accuracy: 0.8898\n",
            "Epoch 13/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2770 - accuracy: 0.8818\n",
            "Epoch 14/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2644 - accuracy: 0.8868\n",
            "Epoch 15/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2594 - accuracy: 0.8886\n",
            "Epoch 16/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2569 - accuracy: 0.8869\n",
            "Epoch 17/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2559 - accuracy: 0.8905\n",
            "Epoch 18/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2531 - accuracy: 0.8881\n",
            "Epoch 19/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2569 - accuracy: 0.8832\n",
            "Epoch 20/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2544 - accuracy: 0.8865\n",
            "Epoch 21/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2487 - accuracy: 0.8865\n",
            "Epoch 22/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2573 - accuracy: 0.8865\n",
            "Epoch 23/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2480 - accuracy: 0.8935\n",
            "Epoch 24/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2509 - accuracy: 0.8882\n",
            "Epoch 25/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2465 - accuracy: 0.8880\n",
            "Epoch 26/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2504 - accuracy: 0.8876\n",
            "Epoch 27/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2499 - accuracy: 0.8872\n",
            "Epoch 28/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2474 - accuracy: 0.8853\n",
            "Epoch 29/150\n",
            "1233/1233 [==============================] - 3s 2ms/step - loss: 0.2597 - accuracy: 0.8861\n",
            "Epoch 30/150\n",
            "1233/1233 [==============================] - 3s 2ms/step - loss: 0.2477 - accuracy: 0.8869\n",
            "Epoch 31/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2461 - accuracy: 0.8841\n",
            "Epoch 32/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2438 - accuracy: 0.8866\n",
            "Epoch 33/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2461 - accuracy: 0.8847\n",
            "Epoch 34/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2512 - accuracy: 0.8867\n",
            "Epoch 35/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2462 - accuracy: 0.8848\n",
            "Epoch 36/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2497 - accuracy: 0.8822\n",
            "Epoch 37/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2429 - accuracy: 0.8877\n",
            "Epoch 38/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2502 - accuracy: 0.8822\n",
            "Epoch 39/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2506 - accuracy: 0.8866\n",
            "Epoch 40/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2463 - accuracy: 0.8881\n",
            "Epoch 41/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2428 - accuracy: 0.8860\n",
            "Epoch 42/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2418 - accuracy: 0.8857\n",
            "Epoch 43/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2424 - accuracy: 0.8875\n",
            "Epoch 44/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2460 - accuracy: 0.8855\n",
            "Epoch 45/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2431 - accuracy: 0.8873\n",
            "Epoch 46/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2419 - accuracy: 0.8881\n",
            "Epoch 47/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2434 - accuracy: 0.8848\n",
            "Epoch 48/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2411 - accuracy: 0.8869\n",
            "Epoch 49/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2389 - accuracy: 0.8879\n",
            "Epoch 50/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2420 - accuracy: 0.8886\n",
            "Epoch 51/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.8867\n",
            "Epoch 52/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2386 - accuracy: 0.8910\n",
            "Epoch 53/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2394 - accuracy: 0.8898\n",
            "Epoch 54/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.8886\n",
            "Epoch 55/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2369 - accuracy: 0.8895\n",
            "Epoch 56/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2432 - accuracy: 0.8855\n",
            "Epoch 57/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.8878\n",
            "Epoch 58/150\n",
            "1233/1233 [==============================] - 3s 2ms/step - loss: 0.2407 - accuracy: 0.8886\n",
            "Epoch 59/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2376 - accuracy: 0.8891\n",
            "Epoch 60/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2381 - accuracy: 0.8876\n",
            "Epoch 61/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2404 - accuracy: 0.8917\n",
            "Epoch 62/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2445 - accuracy: 0.8921\n",
            "Epoch 63/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2380 - accuracy: 0.8921\n",
            "Epoch 64/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2347 - accuracy: 0.8930\n",
            "Epoch 65/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.8915\n",
            "Epoch 66/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2385 - accuracy: 0.8884\n",
            "Epoch 67/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2340 - accuracy: 0.8907\n",
            "Epoch 68/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2349 - accuracy: 0.8925\n",
            "Epoch 69/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.8938\n",
            "Epoch 70/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2359 - accuracy: 0.8938\n",
            "Epoch 71/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2435 - accuracy: 0.8916\n",
            "Epoch 72/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.8912\n",
            "Epoch 73/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2349 - accuracy: 0.8940\n",
            "Epoch 74/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2378 - accuracy: 0.8893\n",
            "Epoch 75/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2354 - accuracy: 0.8921\n",
            "Epoch 76/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2366 - accuracy: 0.8865\n",
            "Epoch 77/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2323 - accuracy: 0.8895\n",
            "Epoch 78/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2386 - accuracy: 0.8912\n",
            "Epoch 79/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2332 - accuracy: 0.8901\n",
            "Epoch 80/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2383 - accuracy: 0.8885\n",
            "Epoch 81/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2367 - accuracy: 0.8905\n",
            "Epoch 82/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2346 - accuracy: 0.8890\n",
            "Epoch 83/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.8936\n",
            "Epoch 84/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2383 - accuracy: 0.8897\n",
            "Epoch 85/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.8945\n",
            "Epoch 86/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2306 - accuracy: 0.8929\n",
            "Epoch 87/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2312 - accuracy: 0.8936\n",
            "Epoch 88/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2337 - accuracy: 0.8903\n",
            "Epoch 89/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2353 - accuracy: 0.8900\n",
            "Epoch 90/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.8916\n",
            "Epoch 91/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2365 - accuracy: 0.8907\n",
            "Epoch 92/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2308 - accuracy: 0.8933\n",
            "Epoch 93/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2322 - accuracy: 0.8877\n",
            "Epoch 94/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2334 - accuracy: 0.8929\n",
            "Epoch 95/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2320 - accuracy: 0.8902\n",
            "Epoch 96/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2316 - accuracy: 0.8918\n",
            "Epoch 97/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2331 - accuracy: 0.8917\n",
            "Epoch 98/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.8951\n",
            "Epoch 99/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2303 - accuracy: 0.8957\n",
            "Epoch 100/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2306 - accuracy: 0.8922\n",
            "Epoch 101/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2315 - accuracy: 0.8925\n",
            "Epoch 102/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2309 - accuracy: 0.8928\n",
            "Epoch 103/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2318 - accuracy: 0.8917\n",
            "Epoch 104/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2368 - accuracy: 0.8884\n",
            "Epoch 105/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.8931\n",
            "Epoch 106/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2314 - accuracy: 0.8953\n",
            "Epoch 107/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2435 - accuracy: 0.8929\n",
            "Epoch 108/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2342 - accuracy: 0.8914\n",
            "Epoch 109/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2285 - accuracy: 0.8954\n",
            "Epoch 110/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2290 - accuracy: 0.8929\n",
            "Epoch 111/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2344 - accuracy: 0.8911\n",
            "Epoch 112/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2324 - accuracy: 0.8944\n",
            "Epoch 113/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2302 - accuracy: 0.8934\n",
            "Epoch 114/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.8951\n",
            "Epoch 115/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2355 - accuracy: 0.8893\n",
            "Epoch 116/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.8969\n",
            "Epoch 117/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2300 - accuracy: 0.8941\n",
            "Epoch 118/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2301 - accuracy: 0.8926\n",
            "Epoch 119/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2282 - accuracy: 0.8924\n",
            "Epoch 120/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2338 - accuracy: 0.8914\n",
            "Epoch 121/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2270 - accuracy: 0.8915\n",
            "Epoch 122/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2294 - accuracy: 0.8949\n",
            "Epoch 123/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2316 - accuracy: 0.8933\n",
            "Epoch 124/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2270 - accuracy: 0.8956\n",
            "Epoch 125/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2316 - accuracy: 0.8973\n",
            "Epoch 126/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2345 - accuracy: 0.8959\n",
            "Epoch 127/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2264 - accuracy: 0.8948\n",
            "Epoch 128/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2287 - accuracy: 0.8968\n",
            "Epoch 129/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2290 - accuracy: 0.8901\n",
            "Epoch 130/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2274 - accuracy: 0.8954\n",
            "Epoch 131/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2276 - accuracy: 0.8955\n",
            "Epoch 132/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2308 - accuracy: 0.8929\n",
            "Epoch 133/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2256 - accuracy: 0.8978\n",
            "Epoch 134/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2277 - accuracy: 0.8964\n",
            "Epoch 135/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2282 - accuracy: 0.8936\n",
            "Epoch 136/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2307 - accuracy: 0.8929\n",
            "Epoch 137/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2261 - accuracy: 0.8931\n",
            "Epoch 138/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2257 - accuracy: 0.8936\n",
            "Epoch 139/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2321 - accuracy: 0.8946\n",
            "Epoch 140/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2240 - accuracy: 0.8942\n",
            "Epoch 141/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2272 - accuracy: 0.8933\n",
            "Epoch 142/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2331 - accuracy: 0.8931\n",
            "Epoch 143/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2245 - accuracy: 0.8958\n",
            "Epoch 144/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2271 - accuracy: 0.8965\n",
            "Epoch 145/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2268 - accuracy: 0.8979\n",
            "Epoch 146/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2280 - accuracy: 0.8930\n",
            "Epoch 147/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2295 - accuracy: 0.8955\n",
            "Epoch 148/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2276 - accuracy: 0.8941\n",
            "Epoch 149/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2258 - accuracy: 0.8975\n",
            "Epoch 150/150\n",
            "1233/1233 [==============================] - 2s 2ms/step - loss: 0.2275 - accuracy: 0.8977\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9e9dbfc50>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmmDKedr76vF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404404df-58a0-4319-b098-fc14030b4413"
      },
      "source": [
        "# 5. Avaliar o modelo\n",
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Acurácia: %.2f' % (accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "386/386 [==============================] - 1s 1ms/step - loss: 0.2256 - accuracy: 0.8984\n",
            "Acurácia: 89.84\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEFcSiM3qRtk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgsKJE0T_M5W"
      },
      "source": [
        "# 6. Fazer predições\n",
        "pred = (model.predict(X) > 0.5).astype(\"int32\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7EdRWz8_cV9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "ddb9fa5c-9629-449c-d255-c3d510ee0879"
      },
      "source": [
        "for i in range(10):\n",
        "  print('%s (real: %d | predito: %d)' % (X[i].tolist(), y[i], pred[i]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d0696881c62f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s (real: %d | predito: %d)'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    }
  ]
}